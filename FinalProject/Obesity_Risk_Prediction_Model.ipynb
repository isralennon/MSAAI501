{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5308793",
   "metadata": {},
   "source": [
    "# Obesity Risk Prediction Model\n",
    "This notebook develops a classification model to predict individuals at high risk for obesity based on demographic and lifestyle features. It includes data loading, preprocessing, exploratory data analysis, model training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa569ea-f935-476a-a9e7-998a66428eb0",
   "metadata": {},
   "source": [
    "### Dataset Information\n",
    "\n",
    "The *Obesity Levels*$\\text{}^{1}$ dataset observed includes estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ea854-0518-40fd-a859-c92043ae5705",
   "metadata": {},
   "source": [
    "This dataset contains the following columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af7b7c-464b-4fa4-b66f-542380ad65d4",
   "metadata": {},
   "source": [
    "| Column                        | Type        | Data Type   | Description                                                                                   |\n",
    "|-------------------------------|-------------|-------------|-----------------------------------------------------------------------------------------------|\n",
    "| **Gender**                    | Feature     | Categorical | \"Gender\"                                                                                      |\n",
    "| **Age**                       | Feature     | Continuous  | \"Age\"                                                                                         |\n",
    "| **Height**                    | Feature     | Continuous  | Height                                                                                        |\n",
    "| **Weight**                    | Feature     | Continuous  | Weight                                                                                        |\n",
    "| **family_history_with_overweight** | Feature | Binary      | \"Has a family member suffered or suffers from overweight?\"                                    |\n",
    "| **FAVC**                      | Feature     | Binary      | \"Do you eat high caloric food frequently?\"                                                    |\n",
    "| **FCVC**                      | Feature     | Integer     | \"Do you usually eat vegetables in your meals?\"                                                |\n",
    "| **NCP**                       | Feature     | Continuous  | \"How many main meals do you have daily?\"                                                      |\n",
    "| **CAEC**                      | Feature     | Categorical | \"Do you eat any food between meals?\"                                                          |\n",
    "| **SMOKE**                     | Feature     | Binary      | \"Do you smoke?\"                                                                               |\n",
    "| **CH2O**                      | Feature     | Continuous  | \"How much water do you drink daily?\"                                                          |\n",
    "| **SCC**                       | Feature     | Binary      | \"Do you monitor the calories you eat daily?\"                                                  |\n",
    "| **FAF**                       | Feature     | Continuous  | \"How often do you have physical activity?\"                                                    |\n",
    "| **TUE**                       | Feature     | Integer     | \"How much time do you use technological devices such as cell phone, videogames, television, computer and others?\" |\n",
    "| **CALC**                      | Feature     | Categorical | \"How often do you drink alcohol?\"                                                             |\n",
    "| **MTRANS**                    | Feature     | Categorical | \"Which transportation do you usually use?\"                                                    |\n",
    "| **NObeyesdad**                | Target      | Categorical | \"Obesity level\"                                                                               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc668fb",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, accuracy_score\n",
    "from statsmodels.stats import anova\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c7535",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "Load the dataset and examine the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('ObesityDataSet_raw.csv')\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3d64f-f149-46aa-8ff9-ff8808b6ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shape of the dataset\n",
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dded08-c324-4b29-9003-1ef9e6f50bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information of the dataset.\n",
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7b932",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "Convert categorical features to numeric, handle missing values, and scale numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0986e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "data = data_raw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e67af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "# Dictionary to store the relationship between original and encoded values\n",
    "value_mapping = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    # Store the mapping of original values to encoded values\n",
    "    value_mapping[column] = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "    #Then, proceed with the replacement.\n",
    "    label_encoders[column] = le\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93549554-e722-44f6-86d7-268334ac81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMappedValues(MyDictionary):\n",
    "    for column, mapping in MyDictionary.items():\n",
    "        # Create an HTML table for each column's mapping\n",
    "        resultText = ''\n",
    "        \n",
    "        # Add rows for each mapping in the dictionary\n",
    "        for original, encoded in mapping.items():\n",
    "            resultText += f'- {original}: {encoded}\\n'\n",
    "        \n",
    "        resultText += '-------------------------'\n",
    "        \n",
    "        # Print the HTML table for the current column\n",
    "        print(f'Values for column: {column}:')\n",
    "        print(resultText)\n",
    "        print('\\n')  # Add space between tables for readability\n",
    "printMappedValues(value_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594bc2fe-8734-48eb-a260-53caf9debc80",
   "metadata": {},
   "source": [
    "### Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0dd8d4-fd60-40ce-800c-402d6eb356ad",
   "metadata": {},
   "source": [
    "| Column                         | Encodings                                                      |\n",
    "|--------------------------------|----------------------------------------------------------------|\n",
    "| **Gender**                     | Female: 0; Male: 1                                             |\n",
    "| **family_history_with_overweight** | no: 0; yes: 1                                         |\n",
    "| **FAVC**                       | no: 0; yes: 1                                                  |\n",
    "| **CAEC**                       | Always: 0; Frequently: 1; Sometimes: 2; no: 3                  |\n",
    "| **SMOKE**                      | no: 0; yes: 1                                                  |\n",
    "| **SCC**                        | no: 0; yes: 1                                                  |\n",
    "| **CALC**                       | Always: 0; Frequently: 1; Sometimes: 2; no: 3                  |\n",
    "| **MTRANS**                     | Automobile: 0; Bike: 1; Motorbike: 2; Public_Transportation: 3; Walking: 4 |\n",
    "| **NObeyesdad**                 | Insufficient_Weight: 0; Normal_Weight: 1; Obesity_Type_I: 2; Obesity_Type_II: 3; Obesity_Type_III: 4; Overweight_Level_I: 5; Overweight_Level_II: 6 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2caac0c",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Explore the distribution of obesity levels and visualize relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2851a5-80c7-4a3b-a2ff-35c743f74b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the number of columns for the grid\n",
    "num_cols = 3\n",
    "num_vars = len(data_raw.columns)\n",
    "num_rows = (num_vars + num_cols - 1) // num_cols  # Calculate required number of rows\n",
    "\n",
    "# Create a grid of subplots for all variables\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 4))\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "for i, column in enumerate(data_raw.columns):\n",
    "    ax = axes[i]\n",
    "    if data_raw[column].dtype == 'object':  # Plot count plot for categorical variables\n",
    "        sns.countplot(x=column, data=data_raw, ax=ax)\n",
    "        ax.set_title(f'Distribution of {column}')\n",
    "        ax.set_xlabel(column)\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.tick_params(axis='x', rotation=45)  # Rotate labels for count plot\n",
    "    else:\n",
    "        # Plot histogram for numerical variables\n",
    "        sns.histplot(data_raw[column], kde=True, ax=ax)\n",
    "        ax.set_title(f'Distribution of {column}')\n",
    "        ax.set_xlabel(column)\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.tick_params(axis='x', rotation=45)  # Rotate labels for histogram\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc229da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(data.corr(), annot=True, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba2a1d",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split\n",
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select refine features selections. Currently all features are being considered. \n",
    "RANDOM_SEED = 42 # Define our random seed\n",
    "\n",
    "X = data.drop('NObeyesdad', axis=1)\n",
    "y = data['NObeyesdad']\n",
    "\n",
    "# Splits the data into training/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,                          # Features variables\n",
    "                                                    y,                          # Target variable\n",
    "                                                    test_size=0.25,             # 25% of the data for test \n",
    "                                                    random_state=RANDOM_SEED)   # Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f2258-7699-4a33-9054-c8bd8cbbc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize training/test data\n",
    "# Standarizing data after splitting to avoid information leakage\n",
    "scaler = StandardScaler() \n",
    "X_train_scale = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scale = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd3240",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "Train multiple models and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b37c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for our confusion matrix \n",
    "def plot_confusion_matrix(_true, _pred, classes, cmap='Blues', title=''):\n",
    "    cm = confusion_matrix(_true, _pred) # set our confusion matrix true and predicted values\n",
    "\n",
    "    # display our confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86b668-0b6e-4360-af2f-37c2516cf0d6",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "rf_model.fit(X_train_scale, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_prediction = rf_model.predict(X_test_scale)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_prediction)\n",
    "print(f'Accuracy: {rf_accuracy}')\n",
    "\n",
    "# Calculate F1 score\n",
    "rf_weighted_f1 = f1_score(y_test, rf_prediction, average='weighted')\n",
    "\n",
    "# call confusion matrix function \n",
    "plot_confusion_matrix(y_test, rf_prediction, rf_model.classes_, title='Random Forest CF Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93eb4bd-85ff-4e77-8267-63b2cdfb0432",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5155ee4-ed2a-43c6-b4d4-5ee0d5131318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the SVM\n",
    "svm_model = SVC(random_state=RANDOM_SEED)\n",
    "svm_model.fit(X_train_scale, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_prediction = svm_model.predict(X_test_scale)\n",
    "\n",
    "# Calculate accuracy\n",
    "svm_accuracy = accuracy_score(y_test, svm_prediction)\n",
    "print(f'Accuracy: {svm_accuracy}')\n",
    "\n",
    "# Calculate F1 score\n",
    "svm_weighted_f1 = f1_score(y_test, svm_prediction, average='weighted')\n",
    "\n",
    "# call confusion matrix function \n",
    "plot_confusion_matrix(y_test, svm_prediction, rf_model.classes_, title='SVM CF Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714f369c-58ff-4966-be46-819c07efc634",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21148862-f432-4c49-8c82-4a99e808b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the Logistic Regression\n",
    "lg_model = LogisticRegression(random_state=RANDOM_SEED)\n",
    "lg_model.fit(X_train_scale, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lg_prediction = lg_model.predict(X_test_scale)\n",
    "\n",
    "# Calculate accuracy\n",
    "lg_accuracy = accuracy_score(y_test, lg_prediction)\n",
    "print(f'Accuracy: {lg_accuracy}')\n",
    "\n",
    "# Calculate F1 score\n",
    "lg_weighted_f1 = f1_score(y_test, lg_prediction, average='weighted')\n",
    "\n",
    "# call confusion matrix function \n",
    "plot_confusion_matrix(y_test, lg_prediction, rf_model.classes_, title='Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb73506-1289-44fe-ac6b-a9790be10ea5",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a1bcd-9958-442e-9c42-3918ec110d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "dt_model.fit(X_train_scale, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "dt_prediction = dt_model.predict(X_test_scale)\n",
    "\n",
    "# Calculate accuracy\n",
    "dt_accuracy = accuracy_score(y_test, dt_prediction)\n",
    "print(f'Accuracy: {dt_accuracy}')\n",
    "\n",
    "# Calculate F1 score\n",
    "dt_weighted_f1 = f1_score(y_test, dt_prediction, average='weighted')\n",
    "\n",
    "# call confusion matrix function \n",
    "plot_confusion_matrix(y_test, dt_prediction, rf_model.classes_, title='Decision Tree CF Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adb314-cf1c-4c47-a802-38ac25b4123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#\n",
    "#   Base Class for the ModelSelector\n",
    "#\n",
    "####################################################################################\n",
    "class ModelSelector:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        testingSize=0.2,\n",
    "        randomSeed=42,\n",
    "        validationSize=0.25,\n",
    "        selectedModel=\"LinearRegression\"\n",
    "):\n",
    "        '''\n",
    "        Definition of parameters:\n",
    "        X: Features\n",
    "        y: Target column\n",
    "        testingSize: Float number from 0 to 1 representing the percentage that will be assigned to the testing set\n",
    "        randomSeed: Value for reproducibility in randomization (Random state)\n",
    "        validationSize: Float number from 0 tp 1 representing the percentage that will be assigned to the validation set\n",
    "        selectedModel: Model to be tested by the class.\n",
    "        '''\n",
    "        self.model_name = selectedModel\n",
    "        self.selectedModels = {\n",
    "            \"LinearRegression\": {\n",
    "                \"model\": lambda X, y: LinearRegression(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            },\n",
    "            \"RandomForestRegressor\": {\n",
    "                \"model\": lambda X, y: RandomForestRegressor(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            },\n",
    "            \"DecisionTreeRegressor\": {\n",
    "                \"model\": lambda X, y: DecisionTreeRegressor(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            },\n",
    "            \"GradientBoostingRegressor\": {\n",
    "                \"model\": lambda X, y: GradientBoostingRegressor(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            },\n",
    "            \"AdaBoostRegressor\": {\n",
    "                \"model\": lambda X, y: AdaBoostRegressor(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            },\n",
    "            \"BaggingRegressor\": {\n",
    "                \"model\": lambda X, y: BaggingRegressor(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            },\n",
    "            \"OLS\": {\n",
    "                \"model\":lambda X, y: sm.OLS(y, X),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit()\n",
    "            },\n",
    "            \"SVR\": {\n",
    "                \"model\": lambda X, y: SVR(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            },\n",
    "            \"MLPRegressor\": {\n",
    "                \"model\": lambda X, y: MLPRegressor(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            },\n",
    "            \"LogisticRegression\":{\n",
    "                \"model\": lambda X, y: LogisticRegression(),\n",
    "                \"fit\": lambda X, y: self.selectedModel.fit(X, y)\n",
    "            }\n",
    "        }\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.testingSize = testingSize\n",
    "        self.randomSeed = randomSeed\n",
    "        self.validationSize = validationSize\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X,\n",
    "            self.y,\n",
    "            test_size=self.testingSize,\n",
    "            random_state=self.randomSeed\n",
    ")\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            test_size=self.validationSize,\n",
    "            random_state=self.randomSeed\n",
    ")\n",
    "        self.selectedModel = self.selectedModels[self.model_name]['model'](self.X_train, self.y_train)\n",
    "\n",
    "    @staticmethod\n",
    "    def getAvailableModels():\n",
    "        return [\n",
    "            \"LinearRegression\",\n",
    "            \"RandomForestRegressor\",\n",
    "            \"DecisionTreeRegressor\",\n",
    "            \"GradientBoostingRegressor\",\n",
    "            \"AdaBoostRegressor\",\n",
    "            \"BaggingRegressor\",\n",
    "            \"OLS\",\n",
    "            \"SVR\",\n",
    "            \"MLPRegressor\",\n",
    "            \"LogisticRegression\"\n",
    "]\n",
    "\n",
    "    def train(self):\n",
    "        self.selectedModel=self.selectedModels[self.model_name]['fit'](self.X_train, self.y_train)\n",
    "        return self.evaluate(self.X_train, self.y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.selectedModel.predict(X)\n",
    "    \n",
    "    def validate(self):\n",
    "        return self.evaluate(self.X_val, self.y_val)\n",
    "    \n",
    "    def test(self):\n",
    "        return self.evaluate(self.X_test, self.y_test)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        return np.round((mse, mae, r2), decimals=2)\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.selectedModel.summary()\n",
    "    \n",
    "    def plotResiduals(self, X, y):\n",
    "        residuals = y - self.predict(X)\n",
    "        sns.scatterplot(x=self.predict(X), y=residuals)\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.title('Predicted Values vs. Residuals')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_residuals(self):\n",
    "        self.plotResiduals(self.X_val, self.y_val)\n",
    "    \n",
    "    def plot_residuals_test(self):\n",
    "        self.plotResiduals(self.X_test, self.y_test)\n",
    "\n",
    "    def plot_residuals_val(self):\n",
    "        self.plotResiduals(self.X_val, self.y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d7fbb-5ccb-4212-848e-c446a1193c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the data into a list of lists\n",
    "resultsData = [['Model',\n",
    "         'Train MSE',\n",
    "         'Train MAE',\n",
    "         'Train R²',\n",
    "         'Validation MSE',\n",
    "         'Validation MAE',\n",
    "         'Validation R²',\n",
    "         'Test MSE',\n",
    "         'Test MAE',\n",
    "         'Test R²'\n",
    "]]\n",
    "\n",
    "for modelName in ModelSelector.getAvailableModels():\n",
    "    currentModel = ModelSelector(X, y, selectedModel=modelName)\n",
    "    trainingResults = currentModel.train()\n",
    "    validationResults = currentModel.validate()\n",
    "    testingResults = currentModel.test()\n",
    "    \n",
    "    # Append each row of model results to the data list\n",
    "    resultsData.append([modelName,\n",
    "                 f'{trainingResults[0]:.4f}', f'{trainingResults[1]:.4f}', f'{trainingResults[2]:.4f}',\n",
    "                 f'{validationResults[0]:.4f}', f'{validationResults[1]:.4f}', f'{validationResults[2]:.4f}',\n",
    "                 f'{testingResults[0]:.4f}', f'{testingResults[1]:.4f}', f'{testingResults[2]:.4f}'])\n",
    "\n",
    "#Printing the data\n",
    "dfResultsData = pd.DataFrame(resultsData)\n",
    "\n",
    "# Print DataFrame as an HTML table\n",
    "html_ResultsData = dfResultsData.to_html()\n",
    "display(HTML(html_ResultsData))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09c5a0",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "Evaluate the best model with detailed metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6d710-7fbb-4162-9642-8b0a2a9cb365",
   "metadata": {},
   "source": [
    "### Models Explored:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72d90e-9080-4592-af6e-5f87fbc7fdf2",
   "metadata": {},
   "source": [
    "| Model                  | Description                                                             | Limitations                                               | Reason for Inclusion                                      |\n",
    "|------------------------|-------------------------------------------------------------------------|-----------------------------------------------------------|-----------------------------------------------------------|\n",
    "| **Random Forest**      | An ensemble model that builds multiple decision trees and combines them for more stable and accurate predictions. | Computationally expensive, especially with large datasets. | Robust to overfitting, captures non-linear relationships, and provides feature importance insights. |\n",
    "| **Support Vector Machine (SVM)** | Finds the hyperplane that best separates classes in the feature space, maximizing the margin between classes. | Sensitive to noise, can be slow on large datasets.         | Effective for high-dimensional data and when clear class boundaries exist. |\n",
    "| **Logistic Regression** | A linear model that predicts class probabilities based on feature values. | Assumes a linear relationship between features and target, may underperform on complex data. | Simple, interpretable, and computationally efficient for baseline performance comparison. |\n",
    "| **Decision Tree**      | A model that splits data into decision nodes based on feature values, creating an interpretable path to classification. | Prone to overfitting without regularization or pruning.   | Easily interpretable, provides a foundation for ensemble methods like Random Forest. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412986c0-a783-4821-a9ef-b8ed11b42e79",
   "metadata": {},
   "source": [
    "*update markdown here: https://stackedit.io/app#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81273346-36f7-45f7-8259-f149e3668124",
   "metadata": {},
   "source": [
    "### Random Forest Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498fef46-d44b-4c6e-92db-c1d5703c0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_prediction))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a3c97-74c3-40d4-95f5-7074f3bcc09c",
   "metadata": {},
   "source": [
    "### SVM Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ea66d-db83-4fa5-93eb-f9f7a66de989",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, svm_prediction))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6569f80-9d16-4d26-8e7f-c5df9c175194",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475cd2f4-9046-45fc-bd67-0c7795cf1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, lg_prediction))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lg_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e14fa7-f1e2-4e85-af85-22decdf7c8f9",
   "metadata": {},
   "source": [
    "### Decision Tree Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718d763-4889-47f7-919b-719406515244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dt_prediction))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, dt_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472d129-db35-4b25-a104-3603d6a84d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This takes a long time to run. \n",
    "\n",
    "i = 30 # Iterations\n",
    "\n",
    "# Lists to store accuracy scores for each model\n",
    "rf_scores = []\n",
    "svm_scores = []\n",
    "lg_scores = []\n",
    "dt_scores = []\n",
    "\n",
    "for i in range(i):\n",
    "    # Splits the data into training/test sets\n",
    "    _x_train, _x_test, _y_train, _y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    # Standardizes training/test data\n",
    "    _x_train_scaled = pd.DataFrame(scaler.fit_transform(_x_train), columns=_x_train.columns, index=_x_train.index)\n",
    "    _x_test_scaled = pd.DataFrame(scaler.transform(_x_test), columns=_x_test.columns, index=_x_test.index)\n",
    "\n",
    "    # Trains and evaluates Random Forest\n",
    "    rf_model.fit(_x_train_scaled, _y_train)\n",
    "    _rf_predictions = rf_model.predict(_x_test_scaled)\n",
    "    _rf_score = accuracy_score(_y_test, _rf_predictions)\n",
    "\n",
    "    # Trains and evaluates SVM \n",
    "    svm_model.fit(_x_train_scaled, _y_train)\n",
    "    _svm_predictions = svm_model.predict(_x_test_scaled)\n",
    "    _svm_score = accuracy_score(_y_test, _svm_predictions)\n",
    "\n",
    "    # Trains and evaluates Logistic Regression \n",
    "    lg_model.fit(_x_train_scaled, _y_train)\n",
    "    _lg_predictions = lg_model.predict(_x_test_scaled)\n",
    "    _lg_score = accuracy_score(_y_test, _lg_predictions)\n",
    "\n",
    "    # Trains and evaluates Decision Tree \n",
    "    dt_model.fit(_x_train_scaled, _y_train)\n",
    "    _dt_predictions = dt_model.predict(_x_test_scaled)\n",
    "    _dt_score = accuracy_score(_y_test, _dt_predictions)\n",
    "\n",
    "    # Collects the scores \n",
    "    rf_scores.append(_rf_score)\n",
    "    svm_scores.append(_svm_score)\n",
    "    lg_scores.append(_lg_score)\n",
    "    dt_scores.append(_dt_score)\n",
    "\n",
    "# Plot histograms of the scores\n",
    "plt.hist(rf_scores, bins=8, alpha=0.6, label='SVM')\n",
    "plt.hist(svm_scores, bins=8, alpha=0.6, label='Decision Tree')\n",
    "plt.hist(lg_scores, bins=8, alpha=0.6, label='SVM')\n",
    "plt.hist(dt_scores, bins=8, alpha=0.6, label='Decision Tree')\n",
    "\n",
    "#  Title, Labels, and Legend\n",
    "plt.legend()\n",
    "plt.xlabel(\"Accuracy Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accuracy Score Distribution of Classifiers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6f3d64",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "Summarize model performance, key findings from feature importance analysis, and potential applications for public health resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1b2b1-d7ed-4c32-b234-8ec6df40adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gather models results, pick the model with best accuracy and identify features to be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8ef92-a4f7-40f1-a3c8-4d36ca542d25",
   "metadata": {},
   "source": [
    "\n",
    "----------------\n",
    "$^{1}$ Mehrparvar, F. (2021). Obesity Levels. Kaggle. Retrieved November 9, 2024, from https://www.kaggle.com/datasets/fatemehmehrparvar/obesity-levels/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
